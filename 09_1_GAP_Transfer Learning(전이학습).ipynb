{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qYJvarnUbfRC",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# GlobalAveragePooling (GAP)\n",
    "- 입력 Feature map의 채널별로 평균값을 추출하여 1 x 1 x channel 의 Feature map을 생성하는 Pooling\n",
    "- `model.add(keras.layers.GlobalAveragePooling2D())`\n",
    "![gap01](figures/09_gap_01.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aVaIaFDfbfRN",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Feature Extraction layer에서 추출한 Feature map을 Classifier layer로 Flatten해서 전달하면 많은 연결노드와 파라미터가 필요하게된다.     \n",
    "GAP를 사용하면 노드와 파라미터의 개수를 효과적으로 줄일 수 있다.\n",
    "- Feature map의 채널수가 많을 경우 GAP를 사용하는 것이 효과적이나 채널수가 적다면 Flatten을 사용하는 것이 좋다.\n",
    "\n",
    "\n",
    "![gap02](figures/09_gap_02.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZEiUymWcbfRZ",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Pretrained Model\n",
    "\n",
    "- 다른 목적을 위해 미리 학습된 모델.(이미 누군가가 만들어서 사용한 모델 API)\n",
    "- Pretrained model을 현재 해결하려는 문제에 이용한다.\n",
    "- 대부분 내가 만들려는 네트워크 모델에 포함시켜 사용한다.\n",
    "    - 이런 방식을 <span style=\"color:orange\">**Transfer Learning (전이 학습)**</span>이라고 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZEiUymWcbfRZ",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Keras에서 제공하는 Pretrained Model \n",
    "- tensorflow.keras.applications 패키지를 통해 제공\n",
    "    - https://www.tensorflow.org/api_docs/python/tf/keras/applications?hl=ko\n",
    "    - Modules\n",
    "        - 각 모델별 입력 Image 전처리 함수 제공\n",
    "    - Functions\n",
    "        - 각 모델 생성함수\n",
    "- 모델 생성함수의 주요 매개변수\n",
    "    - `weights`: 모델의 학습된 weight 지정. \n",
    "        - 기본값- 'imagenet'. ImageNet 데이터셋으로 학습된 weight를 가진 모델 생성\n",
    "    - `include_top`: fully connected layer(분류기)를 포함할지 여부. True 포함시킴, False: 포함 안 시킴\n",
    "        - False를 지정하면 Feature Extractor인 Convolution Layer들로만 구성된 모델이 생성된다.\n",
    "    - `input_shape`: Input(입력) 이미지의 크기 shape. 3D 텐서로 지정. (높이, 너비, 채널). 기본값: (224,224,3)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZEiUymWcbfRZ",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "> 딥러닝 모델기반 application 개발시 대부분 Transfer Learning을 한다.  \n",
    "> 다양한 분야에서 다양한 네트워크 모델들이 구현되어 공개 되어 있으며 학습된 Parameter들도 제공되고 있다.  \n",
    "> [paperswithcode](https://paperswithcode.com/)에서 State Of The Art(SOTA) 논문들과 그 구현된 모델을 확인할 수 있다. \n",
    "\n",
    "> **State Of The Art(SOTA)**: 특정 시점에 특정 분야에서 가장 성능이 좋은 모델을 말한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Keras 제공 Pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## VGG16 Pretrained 모델을 이용해 이미지 분류\n",
    "- Keras에서 제공하는 Pretrain 모델들은 Image Net 데이터셋을 학습 했다.\n",
    "- 최종 Output 결과로 1000개의 class에 대한 확률을 출력한다.\n",
    "    - Dense(units=1000, activation='softmax')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "##### Pretrained Model download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##### 추론할 이미지 로딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "##### 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##### 추론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Transfer learning (전이학습)\n",
    "- 사전에 학습된 신경망의 구조와 파라미터를 재사용해서 새로운 모델(우리가 만드는 모델)의 시작점으로 삼고 해결하려는 문제를 위해 다시 학습시킨다.\n",
    "- 전이 학습을 통해 다음을 해결할 수 있다.\n",
    "    1. 데이터 부족문제\n",
    "        - 딥러닝은 대용량의 학습데이터가 필요하다.\n",
    "        - 충분한 데이터를 수집하는 것은 항상 어렵다.\n",
    "    2. 과다한 계산량\n",
    "        - 신경망 학습에는 엄청난 양의 계산 자원이 필요하다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cj9RRN6QbfRR",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![transfer_learning01](figures/09_transfer_01.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5dXETWizbfRS",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- 미리 학습된(pre-trained) Model을 이용하여 모델을 구성한 뒤 현재 하려는 예측 문제를 해결한다.\n",
    "- 보통 Pretrained Model에서 Feature Extraction 부분을 사용한다.\n",
    "    - Computer Vision 문제의 경우 Bottom 쪽의 Convolution Layer(Feature Extractor)들은 이미지에 나타나는 일반적인 특성을 추출하므로 **다른 대상을 가지고 학습했다고 하더라도 재사용할 수 있다.**\n",
    "    - Top 부분 Layer 부분은 특히 출력 Layer의 경우 대상 데이터셋의 목적에 맞게 변경 해야 하므로 재사용할 수 없다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZnS6S0QPbfRT",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![transfer_learning02](figures/09_transfer_02.png)\n",
    "\n",
    "> **Frozon**: Training시 parameter가 update 되지 않도록 하는 것을 말한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NRLhG6D8bfRb",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Feature extraction 재사용\n",
    "- Pretrained Model에서 Feature Extractor 만 가져오고 추론기(Fully connected layer)만 새로 정의한 뒤 그 둘을 합쳐서 모델을 만든다.\n",
    "- 학습시 직접 구성한 추론기만 학습되도록 한다.\n",
    "    - Feature Extractor는 추론을 위한 Feature 추출을 하는 역할만 하고 그 parameter(weight)가 학습되지 않도록 한다.\n",
    "- Keras에서 모델/레이어의 parameter trainable 속성 변경\n",
    "    -  **Layer.trainable=False**\n",
    "        - Layer의 trainable 속성을 변경\n",
    "    - **Model.trainable=False**\n",
    "        - 모델내의 모든 Layer들의 trainable 속성을 변경\n",
    "    - trainable 속성변경은 **모델 컴파일 전에** 해야 한다.\n",
    "        \n",
    "#### Backbone, Base network\n",
    "전체 네트워크에서 Feature Extraction의 역할을 담당하는 부분을 backbone/base network라고 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 106
    },
    "executionInfo": {
     "elapsed": 4429,
     "status": "ok",
     "timestamp": 1619495130756,
     "user": {
      "displayName": "김성환",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjqNkeEG8Sp5Fmsq56VZoiRsSxwUXmtH2Mb14M3YQA=s64",
      "userId": "02802166581970122576"
     },
     "user_tz": -540
    },
    "id": "u2xEPmIQbfRO",
    "outputId": "e669b58c-b03c-41ef-cf71-2e8503998c4f",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##### 이미지 다운로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gdown --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-04T03:28:45.578697Z",
     "start_time": "2021-11-04T03:28:38.826378Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 106
    },
    "executionInfo": {
     "elapsed": 4429,
     "status": "ok",
     "timestamp": 1619495130756,
     "user": {
      "displayName": "김성환",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjqNkeEG8Sp5Fmsq56VZoiRsSxwUXmtH2Mb14M3YQA=s64",
      "userId": "02802166581970122576"
     },
     "user_tz": -540
    },
    "id": "u2xEPmIQbfRO",
    "outputId": "e669b58c-b03c-41ef-cf71-2e8503998c4f",
    "scrolled": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import gdown\n",
    "import os\n",
    "from zipfile import ZipFile\n",
    "url = 'https://drive.google.com/uc?id=1nBE3N2cXQGwD8JaD0JZ2LmFD-n3D5hVU'\n",
    "fname = 'cats_and_dogs_small.zip'\n",
    "gdown.download(url, fname, quiet=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##### import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "##### 하이퍼파라미터 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##### Util 함수 정의\n",
    "##### 추론함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##### ImageDataGenerator 를 생성하는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "##### train/validation/test 데이터셋 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##### 모델정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##### 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##### 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "##### 새로운 데이터 추론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "miqV_0WSbfRm",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Fine-tuning(미세조정)\n",
    "- Transfer Learning을 위한 Pretrained 모델을 내가 학습시켜야 하는 데이터셋(Custom Dataset)으로 재학습시키는 것을 fine tunning 이라고 한다.\n",
    "- 주어진 문제에 더 적합하도록 Feature Extractor의 가중치들도 조정 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "py7c3rmmbfRm",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Fine tuning 전략\n",
    "![transfer02](figures/09_transfer_03.png)\n",
    "\n",
    "- **세 전략 모두 추론기는 trainable로 한다.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4wtxXsYUbfRn",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**<font size='5'>1. 전체 모델을 전부 학습시킨다.(1번)</font>**    \n",
    "- Pretrained 모델의 weight는 Feature extraction 의 초기 weight 역할을 한다.\n",
    "- **Train dataset의 양이 많고** Pretrained 모델이 학습했던 dataset과 Custom dataset의 class간의 유사성이 **낮은 경우** 적용.\n",
    "- 학습에 시간이 많이 걸린다.\n",
    "    \n",
    "    \n",
    "**<font size='5'>2. Pretrained 모델 Bottom layer들(Input과 가까운 Layer들)은 고정시키고 Top layer의 일부를 재학습시킨다.(2번)</font>**     \n",
    "- **Train dataset의 양이 많고** Pretrained 모델이 학습했던 dataset과 Custom dataset의 class간의 유사성이 **높은 경우** 적용.\n",
    "- **Train dataset의 양이 적고** Pretained 모델이 학습했던 dataset과 custom dataset의 class간의 유사성이 **낮은 경우** 적용\n",
    "    \n",
    "    \n",
    "**<font size='5'>3. Pretrained 모델 전체를 고정시키고 classifier layer들만 학습시킨다.(3번)</font>**      \n",
    "- **Train dataset의 양이 적고** Pretrained 모델이 학습했던 dataset과 Custom dataset의 class간의 유사성이 **높은 경우** 적용.\n",
    "  \n",
    "  \n",
    "> **Custom dataset:** 내가 학습시키고자 하는 dataset \n",
    "> 1번 2번 전략을 Fine tuning 이라고 한다.\n",
    "\n",
    "![fine tuning](figures/09_finetuning.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Model, Layer의 weight 조회\n",
    "- Transfer Learning을 구현하기 위해 기존 학습된 모델(Pretrained Model)의 Layer를 변경시켜야 한다.\n",
    "\n",
    "### Model에서 Layer들 조회\n",
    "- model객체.layers\n",
    "    - 모델을 구성하는 layer 객체들을 담은 리스트\n",
    "- model객체.get_layer(Layer이름:str)\n",
    "    - argument로 전달한 이름의 Layer객체를 반환\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Model과 Layer의 weight들 조회 및 설정\n",
    "- Layer와 Model은 **Weight 조회**와 관련해 세가지 **속성**을 제공\n",
    "    - **weights:** 레이어의 모든 weight 변수들을 담은 리스트\n",
    "        - get_weights() : 레이어의 모든 weight 변수 리스트를 카피해서 반환한다.\n",
    "    - **trainable_weights:** Train(학습)시 업데이트 되는 weights들 리스트\n",
    "    - **non_trainable_weights:** Train(학습)시 업데이트 되지 않는(훈련되지 않는) weights들 리스트\n",
    "- Layer와 Model은 boolean 값을 가지는 속성 **`trainable`**을 제공\n",
    "    - trainable을 **False로** 설정하면 Layer의 weights들이 훈련가능에서 **훈련 불가능** 상태로 변경된다. 이런 상태를 **Frozen-동결** 이라고 하며 학습시 weight들이 업데이트 되지 않는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W9iEOpsCbfRr",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Fine Tuning 예제\n",
    "\n",
    "#### Pretrained 모델 Bottom layer들(Input과 가까운 Layer들)은 고정시키고 Top layer의 일부를 재학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jGgjrGaIbfRr",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Conv_base에서 가장 Top부분에 있는 레이어에 대해 fine-tuning.\n",
    "    - 앞의 layer들은 비교적 일반적이고 재사용 가능한 feature를 학습\n",
    "    - 너무 많은 parameter를 학습시키면 overfitting의 위험이 있음 (특히 새로운 데이터의 수가 적을 때)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "##### 하이퍼파라미터 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##### 모델 정의, 컴파일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "##### 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##### 결과 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##### 최종 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 새로운 데이터 추론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [
    "xFiHZghabfRV",
    "CSgxoXQsbfRV",
    "Lm9kqHnzbfRW",
    "D_gLQChqbfRX",
    "djrKpnvkbfRY",
    "ZEiUymWcbfRZ"
   ],
   "name": "10_GAP_Transfer Learning(전이학습).ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "551.4px",
    "left": "1166px",
    "right": "20px",
    "top": "120px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
